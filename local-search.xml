<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>CS5310_final_project</title>
    <link href="/2024/07/23/CS5310-final-project/"/>
    <url>/2024/07/23/CS5310-final-project/</url>
    
    <content type="html"><![CDATA[<h1 id="Overall"><a href="#Overall" class="headerlink" title="Overall"></a>Overall</h1><p><img src="/2024/07/23/CS5310-final-project/15_2.gif" alt="Water surface simluation + Rainfall"></p><p><img src="/2024/07/23/CS5310-final-project/15_9.gif" alt="PBD by distance constriant"></p><h1 id="1-Image"><a href="#1-Image" class="headerlink" title="1. Image"></a>1. Image</h1><h2 id="Do-something-interesting-to-the-image"><a href="#Do-something-interesting-to-the-image" class="headerlink" title="Do something interesting to the image"></a>Do something interesting to the image</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">../bin/lab1 geraniums.ppm lab1.ppm<br></code></pre></td></tr></table></figure><p>First, I changed the order of green and red to try to output only the leaves, but there was some noise. To fix this issue, two ideas came to mind:</p><ol><li>Blur the original image first, then perform the color separation.</li><li>Use a method similar to shadow mapping’s Percentage-Closer Filtering (PCF), which reduces noise by<br>sampling a circle of surrounding kernels to compute weights when each point is sampled.<br>I can do this change in the last section, so leave this method right here.</li></ol><div style="display: flex; justify-content: center; align-items: center;">  <img src="1_1.jpg" title="Brief output of green leaves" width="300px" height="300px"></div><h2 id="Implement-green-blue-screen-compositing"><a href="#Implement-green-blue-screen-compositing" class="headerlink" title="Implement green&#x2F;blue screen compositing"></a>Implement green&#x2F;blue screen compositing</h2><p>Try to mask the blue and green channel, and try to combine it with the origin background, here is what I got.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">../bin/mask powerpuff.ppm mask.ppm<br></code></pre></td></tr></table></figure><div style="display: flex; justify-content: center; align-items: center;">  <img src="1_2.jpg" title="A regular image" width="200px" height="200px" >  <img src="1_3.jpg" title="A regular image" width="200px" height="200px"></div><p>Trying to use offset dx and dy now. </p><div style="display: flex; justify-content: center; align-items: center;">   <img src="1_4.jpg" title="A regular image" width="200px" height="200px"></div><p>But there are still two problems:</p><ul><li>The front image is so big, trying to add a scale funtion before combine.</li><li>The eyes are missing, because the current blue and green channel blocks much more than except.</li></ul><h3 id="add-scale"><a href="#add-scale" class="headerlink" title="add scale"></a>add scale</h3><p>A new scale function has been added, which now scale the size of the image, the command is below.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">../bin/combine powerpuff.ppm geraniums.ppm mask.ppm 20 -20 0.5 output.ppm<br></code></pre></td></tr></table></figure><div style="display: flex; justify-content: center; align-items: center;">   <img src="1_5.jpg" title="A regular image" width="200px" height="200px"></div><h3 id="updated-mask-algorithm"><a href="#updated-mask-algorithm" class="headerlink" title="updated mask algorithm"></a>updated mask algorithm</h3><p>After studying the image carefully, the eyes are composed of black and white, so I changed the algorithm so that if the color of the rgb is black, or pure white, it always counts as white and doesn’t count as part of the background. Now the result seems better.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">../bin/mask powerpuff.ppm mask.ppm<br></code></pre></td></tr></table></figure><div style="display: flex; justify-content: center; align-items: center;">  <img src="1_6.jpg" title="A regular image" width="200px" height="200px" >  <img src="1_7.jpg" title="A regular image" width="200px" height="200px"></div><h3 id="add-blur-background"><a href="#add-blur-background" class="headerlink" title="add blur background"></a>add blur background</h3><p>It feels like if you can blur the background, the result should be cool. My algorithm just adds a kernel just like the pcf in shadowmap and samples around the circle to average the blur. And below is my final result</p><div style="display: flex; justify-content: center; align-items: center;">  <img src="1_8.jpg" title="A regular image" width="300px" height="300px" ></div><h2 id="Concolusion"><a href="#Concolusion" class="headerlink" title="Concolusion"></a>Concolusion</h2><p>After this assignment we’ve got the basic pixel, colour data structures, written all the relevant functions, the memory allocation for c has really bothered me for a long time, I’m relying too much on smart pointers, this class will give me a deeper understanding of stack and heap allocating memory and freeing it.</p><h1 id="2-Fractals"><a href="#2-Fractals" class="headerlink" title="2. Fractals"></a>2. Fractals</h1><p>This assignment explores the implementation of various fractal and noise generation algorithms using C and C++. The primary focus is on generating images of Mandelbrot and Julia sets, as well as creating cloud patterns using Perlin noise. The document details the challenges faced in integrating C and C++ code, particularly for functions specific to image processing requirements. Additionally, it includes animated visualizations of Julia sets and Perlin noise-based clouds, demonstrating the dynamic behavior of these mathematical constructs. The assignment emphasizes the importance of understanding underlying principles and efficient implementation techniques in computer graphics.</p><h2 id="Image-Structure"><a href="#Image-Structure" class="headerlink" title="Image Structure"></a>Image Structure</h2><p>This part the code I writed is totally in C, because some of the functions in the assignment requirements cannot be implemented in C++, they do not meet the requirements. Image.h can be called with c, or with C++’s extern as below:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-keyword">extern</span> <span class="hljs-string">&quot;C&quot;</span> &#123;<br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&quot;Image.h&quot;</span></span><br>&#125;<br></code></pre></td></tr></table></figure><p>The result as below:</p><div style="display: flex; justify-content: center; align-items: center;">  <img src="2_1.jpg" title="A regular image" width="300px" height="200px" >  <img src="2_2.jpg" title="A regular image" width="300px" height="200px" >  <img src="2_3.jpg" title="A regular image" width="300px" height="200px"></div><p>I used to set the max_value as float [0,1] I found the reason why this doesnot work and cause a crash. At last I found that PPM (P6) set max_value as int [0,255] not as I except.</p><h2 id="Mandelbrot-and-Julia-Sets"><a href="#Mandelbrot-and-Julia-Sets" class="headerlink" title="Mandelbrot and Julia Sets"></a>Mandelbrot and Julia Sets</h2><p>based on the requirement below: </p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs txt">A picture of the complete Mandelbrot set in an appropriate rectangle.<br>A picture of a Julia set defined by c = 0.7454054 + i*0.1130063 in an appropriate rectangle.<br></code></pre></td></tr></table></figure><p>The assignment didn’t involve considering colors, so the result as below.</p><div style="display: flex; justify-content: center; align-items: center;">  <img src="2_4.jpg" title="A regular image" width="300px" height="200px" >  <img src="2_5.jpg" title="A regular image" width="300px" height="200px" >  <img src="2_6.jpg" title="A regular image" width="300px" height="200px"></div><p>Here are something I wanna mentioned:  </p><ol><li>I change the <code>mandeltest.c</code>to <code>mandeltest.cpp</code>, because the implantation of <code>fractals.cpp/h</code> I use c++.</li><li>Normal equation of this two method to update z is $z^2 + c$ , but the lab instruction is $z^2 - c$. I choose to use the lab instruction.</li><li>To conform to the coordinate system required for the assignment, I inverted my y-axis.</li></ol><h3 id="add-something-I-am-interested-in-ImageMagick"><a href="#add-something-I-am-interested-in-ImageMagick" class="headerlink" title="add something I am interested in : ImageMagick"></a>add something I am interested in : ImageMagick</h3><p>I wanna to see the movement of julia function like output a video, there are two method comes to my mind : 1. build a graphic pipeline or output lots of ppm and combine them as a JIF. I am too lasy to select the second method. Click the figure below can jump to the website I store the GIF.</p><div style="display: flex; justify-content: center; align-items: center;">  <img src="2_11.gif" title="A regular image" width="900px" height="500px" ></div><h2 id="Fractal-Noise-Perlin"><a href="#Fractal-Noise-Perlin" class="headerlink" title="Fractal Noise: Perlin"></a>Fractal Noise: Perlin</h2><h3 id="single-level-Perlin"><a href="#single-level-Perlin" class="headerlink" title="single-level Perlin"></a>single-level Perlin</h3><p>Generates a cloud pattern using a single-level Perlin noise algorithm and applies it to an image. In my main.cpp it is generateCloudsPerlin.</p><div style="display: flex; justify-content: center; align-items: center;">  <img src="2_8.jpg" title="A regular image" width="300px" height="200px" ></div><h3 id="multi-level-Perlin"><a href="#multi-level-Perlin" class="headerlink" title="multi-level Perlin"></a>multi-level Perlin</h3><p>Generates a cloud pattern using a multi-level Perlin noise algorithm and applies it to an image. In my <code>main.cpp</code> it is <code>generateCloudsPerlin2</code>.</p><div style="display: flex; justify-content: center; align-items: center;">  <img src="2_12.gif" title="A regular image" width="900px" height="500px" ></div><h2 id="animation-of-sky-and-cloud"><a href="#animation-of-sky-and-cloud" class="headerlink" title="animation of sky and cloud"></a>animation of sky and cloud</h2><p>Generates a cloud pattern using a multi-level Perlin noise algorithm with time-based animation and distinguishes between cloud and sky regions. In my main.cpp it is <code>generateCloudsPerlin4</code>.</p><div style="display: flex; justify-content: center; align-items: center;">  <img src="2_13.gif" title="A regular image" width="900px" height="500px" ></div><h1 id="3-Graphic-Primitives"><a href="#3-Graphic-Primitives" class="headerlink" title="3. Graphic Primitives"></a>3. Graphic Primitives</h1><h2 id="basic-point-line-ellipse-and-circle"><a href="#basic-point-line-ellipse-and-circle" class="headerlink" title="basic point, line, ellipse and circle"></a>basic point, line, ellipse and circle</h2><p>Here are the RESULTS of all the test case, ellipse and circles I used the given template.</p><div style="display: flex; justify-content: center; align-items: center;">  <img src="3_1.jpg" title="A regular image" width="400px" height="200px" >  <img src="3_2.jpg" title="A regular image" width="400px" height="200px" >  <img src="3_3.jpg" title="A regular image" width="400px" height="200px"></div><div style="display: flex; justify-content: center; align-items: center;">  <img src="3_4.jpg" title="A regular image" width="300px" height="200px" >  <img src="3_5.jpg" title="A regular image" width="300px" height="200px" ></div><h2 id="anti-alias-SSAA"><a href="#anti-alias-SSAA" class="headerlink" title="anti-alias: SSAA"></a>anti-alias: SSAA</h2><p>I try to implement a anti-alias method: SSAA. Here is the meaning of all the graph.</p><ol><li>Because our data of ppm is integer 2D array in Image.h. So I try to implement SSAA at integer base, which mean use a filter get random points around the target point, calculate the result. The result is not what I want, so I change the method to float base.</li><li>Float base SSAA means random up and down 1 to sample. If the random result is $x &#x3D; x + 0.1 $ 0.1 is the random SSAA, which means $dx &#x3D; x + 1$. the result as below use 2X SSAA.</li><li>This image is interesting, I randomized the rgb separately, so it produced the effect below, then I set the random seed of the rgb to one and it didn’t produce this error.</li></ol><div style="display: flex; justify-content: center; align-items: center;">  <img src="3_6.jpg" title="A regular image" width="400px" height="200px" >  <img src="3_7.jpg" title="A regular image" width="400px" height="200px" >  <img src="3_8.jpg" title="A regular image" width="400px" height="200px"></div><ol start="4"><li>The rest 3 image is different level of SSAA sample rate.</li></ol><div style="display: flex; justify-content: center; align-items: center;">  <img src="3_9.jpg" title="A regular image" width="400px" height="200px">  <img src="3_10.jpg" title="A regular image" width="400px" height="200px">  <img src="3_11.jpg" title="A regular image" width="400px" height="200px"></div><h2 id="draw-a-sphere"><a href="#draw-a-sphere" class="headerlink" title="draw a sphere"></a>draw a sphere</h2><h3 id="vertex-of-sphere"><a href="#vertex-of-sphere" class="headerlink" title="vertex of sphere"></a>vertex of sphere</h3><p>build the vertex of sphere by formula.</p><div style="display: flex; justify-content: center; align-items: center;">  <img src="3_12.jpg" title="A regular image" width="400px" height="400px"></div><h3 id="triangle-of-sphere"><a href="#triangle-of-sphere" class="headerlink" title="triangle of sphere"></a>triangle of sphere</h3><p>I added a triangle on top of the original line, point, circles… connect each three point to a triangle and result got below. I rebuilt a new tuple, the triangle, as the most basic tuple for linking the three points so that I could render the entire circle.</p><div style="display: flex; justify-content: center; align-items: center;">  <img src="3_13.jpg" title="A regular image" width="400px" height="400px"></div><h3 id="fill-the-triangle"><a href="#fill-the-triangle" class="headerlink" title="fill the triangle"></a>fill the triangle</h3><div style="display: flex; justify-content: center; align-items: center;">  <img src="3_14.jpg" title="A regular image" width="400px" height="400px"></div><p>with the fill method, I can prevent there is a light on the top of the ball, simply by add a rgb change method in for loop of filling the triangles. After completing the whole project and looking back at it as I was finishing up my final project, I realised that this was a simple implementation of shadow depth.</p><div style="display: flex; justify-content: center; align-items: center;">  <img src="3_15.jpg" title="A regular image" width="400px" height="400px"></div><h1 id="4-Scanline-Fill"><a href="#4-Scanline-Fill" class="headerlink" title="4. Scanline Fill"></a>4. Scanline Fill</h1><h2 id="Basic-point-line-ellipse-and-circle"><a href="#Basic-point-line-ellipse-and-circle" class="headerlink" title="Basic point, line, ellipse and circle"></a>Basic point, line, ellipse and circle</h2><p>Here are the RESULTS of all the test case. From this week, I am a little bit busy, I need to work 12 hours a day, The amount of my report will be less, but the work I done is not (I wish).</p><div style="display: flex; justify-content: center; align-items: center;">  <img src="4_1.jpg" title="A regular image" width="200px" height="200px">  <img src="4_2.jpg" title="A regular image" width="200px" height="200px">  <img src="4_5.jpg" title="A regular image" width="200px" height="200px"></div><h2 id="Make-primitives-move"><a href="#Make-primitives-move" class="headerlink" title="Make primitives move"></a>Make primitives move</h2><p>I attempted to integrate the primitives, including the ellipses, circles, and lines that the professor taught us this time, along with the triangles I previously created and the mesh formula composed of triangles. I combined them all to be called together. Then, I used the same method as before to generate a GIF of my results.</p><h3 id="The-explosion"><a href="#The-explosion" class="headerlink" title="The explosion"></a>The explosion</h3><div style="display: flex; justify-content: center; align-items: center;">  <img src="4_6.gif" title="A regular image" width="400px" height="400px"></div><h3 id="Sphere-mesh"><a href="#Sphere-mesh" class="headerlink" title="Sphere mesh"></a>Sphere mesh</h3><div style="display: flex; justify-content: center; align-items: center;">  <img src="4_7.gif" title="A regular image" width="400px" height="400px"></div><h2 id="Real-time-renderer"><a href="#Real-time-renderer" class="headerlink" title="Real time renderer"></a>Real time renderer</h2><p>This week, I completed the basic structure for graphics and transformed the primitives into dynamic ones that I like. I also attempted to integrate the entire structure into Qt, allowing me to see the changes in real-time. I am very interested in real-time rendering, and this can be considered the first step. It’s really fascinating to implement a real-time renderer by myself, I’m excited and starting to try it.</p><h3 id="The-basic-interface-of-my-UI"><a href="#The-basic-interface-of-my-UI" class="headerlink" title="The basic interface of my UI"></a>The basic interface of my UI</h3><p>The current overall structure is too basic and not very modern. However, I will make this structure more modern in the upcoming assignments.</p><div style="display: flex; justify-content: center; align-items: center;">  <img src="4_3.jpg" title="A regular image" width="700px" height="400px"></div><h3 id="Apply-anti-anlysis-in-UI"><a href="#Apply-anti-anlysis-in-UI" class="headerlink" title="Apply anti-anlysis in UI"></a>Apply anti-anlysis in UI</h3><p>The current anti-aliasing method is too basic. In the upcoming assignments, I will add additional parameter controls, allowing for toggling on and off, selecting anti-aliasing multipliers, and choosing different methods.</p><div style="display: flex; justify-content: center; align-items: center;">  <img src="4_4.jpg" title="A regular image" width="700px" height="400px"></div><h1 id="5-Transformations-and-Viewing"><a href="#5-Transformations-and-Viewing" class="headerlink" title="5. Transformations and Viewing"></a>5. Transformations and Viewing</h1><h2 id="Basic-task"><a href="#Basic-task" class="headerlink" title="Basic task"></a>Basic task</h2><ol><li>The first part of the assignment is to build a matrix library as outlined in the system specification.</li><li>The second part of the assignment is to create a 2D view matrix function and demonstrate that it works using the test function.</li><li>The third task is to create a 3D view matrix function and demonstrate it works using the test function.</li></ol><p>Note that my third example already incorrect! But I did not notice it at that time! It should be look down to the square not up.</p><div style="display: flex; justify-content: center; align-items: center;">  <img src="5_1.jpg" title="A regular image" width="400px" height="200px">  <img src="5_2.jpg" title="A regular image" width="400px" height="200px">  <img src="5_3.jpg" title="A regular image" width="300px" height="200px"></div><h2 id="The-formula-of-View-2D-and-3D"><a href="#The-formula-of-View-2D-and-3D" class="headerlink" title="The formula of View 2D and 3D"></a>The formula of View 2D and 3D</h2><p>When I review the result I found that at that time my program is already incorrect, my MVP matrix is wrong. This part of the assignment confused me for a long time, and I am summarising all the steps of 2D and 3D MVP matrix transformation in case I kmaek the same mistake in the furthure.</p><h3 id="2D-View-Transformation-Process"><a href="#2D-View-Transformation-Process" class="headerlink" title="2D View Transformation Process"></a>2D View Transformation Process</h3><ol><li><p><strong>Initialization</strong>:</p><ul><li>Start by identifying the view rectangle’s height in world coordinates based on the screen dimensions and aspect ratio:<br>$$<br>dy &#x3D; \frac{view.dx \cdot view.screeny}{view.screenx}<br>$$</li></ul></li><li><p><strong>Translation</strong>:</p><ul><li>Translate the View Reference Point (VRP) to the origin by applying a translation matrix that moves the VRP to $(0, 0)$:<br>$$<br>T(-V0_x, -V0_y)<br>$$</li></ul></li><li><p><strong>Rotation</strong>:</p><ul><li>Rotate the coordinate system such that the x-axis aligns with the given view direction vector (x). This is achieved by constructing a rotation matrix that aligns (x) and negates (y):<br>$$<br>R(nx, -ny)<br>$$</li></ul></li><li><p><strong>Scaling</strong>:</p><ul><li>Scale the coordinate system to map the view rectangle dimensions to screen coordinates. This involves scaling the x-dimension by $\frac{screenx}{dx}$ and the y-dimension by $\frac{-screeny}{dy}$ (to account for screen coordinate inversion):<br>$$<br>S\left(\frac{C}{du}, \frac{-R}{dv}\right)<br>$$</li></ul></li><li><p><strong>Translation to Screen Center</strong>:</p><ul><li>Finally, translate the coordinate system to center the view on the screen. This is done by translating by half the screen width and height:<br>$$<br>T\left(\frac{C}{2}, \frac{R}{2}\right)<br>$$</li></ul></li><li><p><strong>Combining Transformations</strong>:</p><ul><li>Combine all the above transformations in the correct order: scale, rotate, and then translate, to form the final View Transformation Matrix (VTM).</li></ul></li></ol><h3 id="3D-View-Transformation-Process"><a href="#3D-View-Transformation-Process" class="headerlink" title="3D View Transformation Process"></a>3D View Transformation Process</h3><ol><li><p><strong>Initialization</strong>:</p><ul><li>Start by setting the View Transformation Matrix (VTM) to the identity matrix.</li></ul></li><li><p><strong>Translation of VRP</strong>:</p><ul><li>Translate the View Reference Point (VRP) to the origin. This is done by applying a translation matrix that moves the VRP to $(0, 0, 0)$:<br>$$<br>T(-VRP_x, -VRP_y, -VRP_z)<br>$$</li></ul></li><li><p><strong>Constructing the Rotation Matrix</strong>:</p><ul><li>Calculate the orthonormal basis vectors (u), (v), and (w) from the View Plane Normal (VPN) and the View Up Vector (VUP). Normalize (w) (aligned with VPN), then compute (u) as the cross product of VUP and (w), and finally compute (v) as the cross product of (w) and (u):<br>$$<br>w &#x3D; \frac{VPN}{||VPN||}<br>$$<br>$$<br>u &#x3D; \frac{VUP \times w}{||VUP \times w||}<br>$$<br>$$<br>v &#x3D; w \times u<br>$$</li></ul></li><li><p><strong>Applying the Rotation</strong>:</p><ul><li>Form a rotation matrix using the basis vectors (u), (v), and (w), and apply it to align the coordinate system with the view direction.</li></ul></li><li><p><strong>Translation to COP</strong>:</p><ul><li>Translate the Center of Projection (COP) to the origin by applying a translation matrix along the z-axis by the distance (d) (viewing distance):<br>$$<br>T(0, 0, d)<br>$$</li></ul></li><li><p><strong>Scaling to NDC (CVV)</strong>:</p><ul><li>Scale the coordinate system to map the view volume to the Canonical View Volume (CVV), which in normalized device coordinates (NDC) is the unit cube. This involves scaling by the dimensions (du), (dv), and the depth (distance from VRP to the back clipping plane):<br>$$<br>S\left(\frac{2d}{du \cdot depth}, \frac{2d}{dv \cdot depth}, \frac{1}{depth}\right)<br>$$</li></ul></li><li><p><strong>Perspective Projection</strong>:</p><ul><li>Apply perspective projection to the coordinate system to account for perspective foreshortening. This is done by scaling the z-coordinate appropriately:<br>$$<br>P\left(\frac{d}{depth}\right)<br>$$</li></ul></li><li><p><strong>Scaling to Screen Coordinates</strong>:</p><ul><li>Scale the coordinate system to map the NDC to screen coordinates. This involves scaling by half the screen width and height, and flipping the y-axis to match screen coordinates:<br>$$<br>S\left(\frac{-screenx}{2 \cdot (d &#x2F; depth)}, \frac{-screeny}{2 \cdot (d &#x2F; depth)}, 1\right)<br>$$</li></ul></li><li><p><strong>Final Translation to Image Coordinates</strong>:</p><ul><li>Translate the coordinate system to position it correctly on the screen. This involves translating by half the screen width and height:<br>$$<br>T\left(\frac{screenx}{2}, \frac{screeny}{2}\right)<br>$$</li></ul></li><li><p><strong>Combining Transformations</strong>:</p><ul><li>Combine all the above transformations in the correct order: translate, rotate, translate to COP, scale to NDC, apply perspective, scale to screen coordinates, and finally translate to image coordinates, to form the final View Transformation Matrix (VTM).</li></ul></li></ol><p>This is extremely important to me.</p><h3 id="First-test-example-animation"><a href="#First-test-example-animation" class="headerlink" title="First test example animation"></a>First test example animation</h3><div style="display: flex; justify-content: center; align-items: center;">  <img src="5_4.gif" title="A regular image" width="500px" height="300px"></div><h3 id="Second-test-example-animation"><a href="#Second-test-example-animation" class="headerlink" title="Second test example animation"></a>Second test example animation</h3><div style="display: flex; justify-content: center; align-items: center;">  <img src="5_5.gif" title="A regular image" width="400px" height="400px"></div><h1 id="6-Hierarchical-Modeling"><a href="#6-Hierarchical-Modeling" class="headerlink" title="6. Hierarchical Modeling"></a>6. Hierarchical Modeling</h1><h2 id="basic-assignment"><a href="#basic-assignment" class="headerlink" title="basic assignment"></a>basic assignment</h2><p>My result of this assignment below.</p><div style="display: flex; justify-content: center; align-items: center;">  <img src="6_1.jpg" title="A regular image" width="400px" height="200px">   <img src="6_2.jpg" title="A regular image" width="400px" height="200px"></div><h2 id="Polygon-Transformation-and-Rendering-Process"><a href="#Polygon-Transformation-and-Rendering-Process" class="headerlink" title="Polygon Transformation and Rendering Process"></a>Polygon Transformation and Rendering Process</h2><h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><p>The process of transforming and rendering polygons is the bug I solved for most of the time. The key problem is in the order of components involved are the Local Transformation Matrix (LTM), Global Transformation Matrix (GTM), and View Transformation Matrix (VTM).</p><h3 id="Transformation-Matrices"><a href="#Transformation-Matrices" class="headerlink" title="Transformation Matrices"></a>Transformation Matrices</h3><ol><li><p><strong>LTM (Local Transformation Matrix)</strong>:</p><ul><li>Initially set to identity.</li><li>Used to transform the polygon from its local coordinate space to a global coordinate space.</li></ul></li><li><p><strong>GTM (Global Transformation Matrix)</strong>:</p><ul><li>Combines the LTM with the current GTM to obtain a temporary GTM (<code>tempGTM</code>).</li><li>This combined transformation is used to place the object correctly in the scene.</li></ul></li><li><p><strong>VTM (View Transformation Matrix)</strong>:</p><ul><li>Applied to transform the polygon from the global coordinate space to the view coordinate space.</li><li>Ensures the polygon is correctly oriented relative to the camera&#x2F;viewer.</li></ul></li></ol><h3 id="Process-Steps"><a href="#Process-Steps" class="headerlink" title="Process Steps"></a>Process Steps</h3><ol><li><p><strong>Initialization</strong>:</p><ul><li>The LTM and GTM are initialized to identity matrices.</li></ul></li><li><p><strong>Transformation</strong>:</p><ul><li>For each polygon object:<ul><li>A temporary GTM (<code>tempGTM</code>) is calculated by multiplying the current GTM with the LTM.</li><li>The polygon is transformed using <code>tempGTM</code> to position it correctly in the scene.</li></ul></li></ul></li><li><p><strong>Shading</strong>:</p><ul><li>Depending on the shading model (e.g., Gouraud shading), colors are calculated for each vertex.</li><li>This involves lighting calculations to determine the vertex colors.</li></ul></li><li><p><strong>View Transformation</strong>:</p><ul><li>The VTM is applied to the polygon to transform it into the view space.</li><li>The polygon is then normalized to ensure it fits within the viewable area.</li></ul></li><li><p><strong>Rendering</strong>:</p><ul><li>The polygon is rendered based on the shading model which will used in the later project, but now everything is ShadeConst.</li></ul></li><li><p><strong>Cleanup</strong>:</p><ul><li>The temporary polygon data is cleared after rendering to prepare for the next object.</li></ul></li></ol><h2 id="try-to-make-the-image-move"><a href="#try-to-make-the-image-move" class="headerlink" title="try to make the image move"></a>try to make the image move</h2><div style="display: flex; justify-content: center; align-items: center;">  <img src="6_3.gif" title="A regular image" width="600px" height="400px"></div><h1 id="7-Bezier-Curves-and-Surfaces"><a href="#7-Bezier-Curves-and-Surfaces" class="headerlink" title="7. Bezier Curves and Surfaces"></a>7. Bezier Curves and Surfaces</h1><p>When I first started implementing Bezier curves and surfaces, I treated them as separate modules, at the same level as lines and polygons. Later, with Bruce’s correction, I realized that Bezier curves are just tools for generating modules or lines. After generating lines or polygons, they still need to be passed to polygons or polylines as basic primitives for rendering, rather than being independent.</p><p>In my subsequent code, I found that this approach has the advantage of being easier to maintain. Writing them separately would require duplicating all the polygon methods, which would be cumbersome.</p><div style="display: flex; justify-content: center; align-items: center;">  <img src="7_3.jpg" title="A regular image" width="400px" height="150px">  <img src="7_4.jpg" title="A regular image" width="400px" height="150px">  <img src="7_5.jpg" title="A regular image" width="400px" height="150px"></div><h2 id="Updated-the-Interface"><a href="#Updated-the-Interface" class="headerlink" title="Updated the Interface"></a>Updated the Interface</h2><p>I have updated my UI to display the antialiasing multiplier and the toggle option, as shown in the image. Additionally, I have integrated module drawing into the real-time transformation Qt UI.</p><div style="display: flex; justify-content: center; align-items: center;">  <img src="7_1.gif" title="A regular image" width="800px" height="400px"></div><div style="display: flex; justify-content: center; align-items: center;">  <img src="7_2.gif" title="A regular image" width="800px" height="400px"></div><h1 id="8-Z-buffer-Rendering"><a href="#8-Z-buffer-Rendering" class="headerlink" title="8. Z-buffer Rendering"></a>8. Z-buffer Rendering</h1><h2 id="Basic-task-1"><a href="#Basic-task-1" class="headerlink" title="Basic task"></a>Basic task</h2><p>This week you need to implement any z-buffer related functions you’ve skipped so far. They are interspersed throughout the the graphics system document Download graphics system document, so scan through it to see the various places that need to change.  Otherwise, it has not changed from the last project.</p><p>Here are the basic two testfile output.</p><div style="display: flex; justify-content: center; align-items: center;">  <img src="8_2.jpg" title="A regular image" width="400px" height="200px">  <img src="8_3.jpg" title="A regular image" width="400px" height="200px"></div><h2 id="z-buffer-simluate-blending"><a href="#z-buffer-simluate-blending" class="headerlink" title="z-buffer simluate blending"></a>z-buffer simluate blending</h2><p>After implemented z-buffer, I had a bold idea, the usual method of blending that people use is to add the alpha channel, could I just run the blending directly on the zbuffer without adding the alpha channel? Here’s what I’m going to do. Change the current algorithm: if 1&#x2F;zbuffer is larger than the zbuffer stored in the image, replace it directly, but instead put the two colours together and press them to a certain weight.</p><ol><li>For each pixel, if the depth of the new color is less than the current depth in the z-buffer, calculate the blended color using the depth values as weights.</li><li>Update the z-buffer and color buffer with the blended color and new depth.</li></ol><div style="display: flex; justify-content: center; align-items: center;">  <img src="8_1.jpg" title="A regular image" width="400px" height="200px"></div><p>The result is a little bit wired, try to find the issue after implement the alpha channel.</p><h2 id="Insert-it-in-my-UI"><a href="#Insert-it-in-my-UI" class="headerlink" title="Insert it in my UI"></a>Insert it in my UI</h2><p>Do the same to the project before </p><p><img src="/2024/07/23/CS5310-final-project/8_4.gif"></p><h1 id="9-Lighting-and-Shading"><a href="#9-Lighting-and-Shading" class="headerlink" title="9. Lighting and Shading"></a>9. Lighting and Shading</h1><p>Basic light algorithm implementations such as gourand shading, depth shading, etc. were implemented this week. Also accessed the extra api to enable calling ply files, which is really interesting, I’m going to put some notorious graphics content in there now, oh yeah, and fixed a major bug, with Bruce’s instructions I realised that my fillscan actually didn’t detect if y was out of bounds! No wonder I’ve been having the inexplicable falling out of memory failure bug before.</p><h2 id="basic-result"><a href="#basic-result" class="headerlink" title="basic result"></a>basic result</h2><div style="display: flex; justify-content: center; align-items: center;">  <img src="9_1.jpg" title="A regular image" width="400px" height="150px">  <img src="9_2.jpg" title="A regular image" width="400px" height="150px">  <img src="9_3.jpg" title="A regular image" width="400px" height="150px"></div><h2 id="Water-Simulation"><a href="#Water-Simulation" class="headerlink" title="Water Simulation"></a>Water Simulation</h2><h3 id="introduction"><a href="#introduction" class="headerlink" title="introduction"></a>introduction</h3><p>After assignment Lighting and Shading, we already have light, so it is time for me to start building the surface of the sea. I really like things in nature like ocean, moon light, montains and I wanted to realise it in this assignment.</p><h3 id="Mesh-the-water-surface"><a href="#Mesh-the-water-surface" class="headerlink" title="Mesh the water surface"></a>Mesh the water surface</h3><p>I made a 50 x 50 size mesh in xz plane, and each set have four points, combine as a polygon, all the normal of polygon initialize as 0,1,0, which is up.</p><p><img src="/2024/07/23/CS5310-final-project/9_4.jpg" alt="mesh of my water surface"></p><h3 id="Simulation-the-water-by-Sinusoids-Wave"><a href="#Simulation-the-water-by-Sinusoids-Wave" class="headerlink" title="Simulation the water by Sinusoids Wave"></a>Simulation the water by Sinusoids Wave</h3><p>The idea of modelling the undulation of water surfaces using a combination of sequences of sine wave curves of high and low amplitude was first introduced by Max [Max 1981] in 1981. By modelling the surface of a body of water using heights, the general formula for the height y &#x3D; h(x, z, t) computed at each point (x, z) at time t by the Sinusoids Wave (SW) based method is:<br>Sinusoids Wave is now rarely used directly in the field of water rendering, and the industry tends to favour the use of its evolution, Gerstner Wave.[1] [2]</p><p>$$h(x, z, t) &#x3D; -y_0 + \sum_{i&#x3D;1}^{N_w} A_i \cos(k_{ix} x + k_{iz} z - \omega_i t)$$  </p><ul><li>$h(x,z,t)$ : the height <code>y</code> of the wave when time <code>t</code> and position $(x,z)$.  </li><li>$Nw$: total number of waves which is used to make the system more complex. </li><li>$Ai$: each wave’s amplitude.</li><li>$y_0$: the starting <code>y</code> position of each result, I set it as 0.</li></ul><p>The formula above is calculate by 1D Sinusoids Wave below, which is easy to understand:<br>$$y &#x3D; Asin(k_{ix}x+w_it)$$</p><p>Use $sin$ and $cos$ will get same simluation result, the only difference is the position of starting wave. </p><div style="display: flex; justify-content: center; align-items: center;">  <img src="9_7.gif" title="A regular image" width="400px" height="200px"></div><p>Depth Shading and Ground Shading in <code>real time</code> below.</p><p><img src="/2024/07/23/CS5310-final-project/9_5.gif" alt="Depth Shading + Sinusoids Wave"></p><p><img src="/2024/07/23/CS5310-final-project/9_6.gif" alt="Ground Shading + Sinusoids Wave"></p><p>The result is not continuous, but it is as expected, because each face is populated by that face’s own <code>normal</code>, so the two faces don’t have the same <code>normal</code> so there will be this difference.<br>I have two idea to avoid this:  </p><ol><li>Normal Mapping: I’m going to output the <code>normal</code> mapping, by representing the normals of all the points in rgb and thus outputting them.</li><li>Offline Renderer: I am going to build a offline renderer, and 100 times the amount of the triangles.</li></ol><p>Normally normal mapping requires storage and texture, but we don’t have texture yet, I’m going to implement this step after texture. So I build a offline renderer and render the image for 1 second and here is the result.<br><img src="/2024/07/23/CS5310-final-project/9_8.jpg" alt="Ground Shading + Sinusoids Wave (offline)"></p><p>I built a realtime macro, which will change all the function and interface to realtime or offline, make me much more eaiser to control the code. For example, the code below is changing drawing speed of the code.</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-keyword">if</span>(realtime) <span class="hljs-comment">// realtime rendering</span><br>    timer-&gt;<span class="hljs-built_in">start</span>(<span class="hljs-number">10</span>); <span class="hljs-comment">// 10 ms per draw</span><br><span class="hljs-keyword">else</span> <span class="hljs-comment">// offline rendering</span><br>    timer-&gt;<span class="hljs-built_in">start</span>(<span class="hljs-number">1000</span>); <span class="hljs-comment">// 1000 ms per draw</span><br></code></pre></td></tr></table></figure><p>Its really fun, I try to change the formula not directly implement the height by x and y, but input the $\sqrt{x^2+z^2}$ replace x or z.</p><p><img src="/2024/07/23/CS5310-final-project/9_9.gif" alt="Ground Shading + Sinusoids Wave (offline)"></p><p>Then try to put the center point to the center of the water surface, simply calculate the distance by $\sqrt{(x-\frac{width}{4})^2+(z-\frac{height}{4})^2}$, width and height are the number of polygon’s vertex in my algorithm.</p><p><img src="/2024/07/23/CS5310-final-project/9_10.gif" alt="Ground Shading + Sinusoids Wave (offline)"></p><h1 id="10-Texture"><a href="#10-Texture" class="headerlink" title="10. Texture"></a>10. Texture</h1><p>The implementation of textures should be the easiest, as it is done exactly like the colors, using linear interpolation. The only difference is that for textures, I use a 2D texture map, and instead of interpolating colors, I interpolate texture coordinates. I wrote a new function to read the texture, and the test results are as follows.</p><div style="display: flex; justify-content: center; align-items: center;">  <img src="10_1.jpg" title="A regular image" width="300px" height="300px">  <img src="10_2.gif" title="A regular image" width="500px" height="300px"></div><p>Combining three different kinds of waveforms to make the picture random enough, and also combine the texture we calculate just now. Here is the result of.</p><p><img src="/2024/07/23/CS5310-final-project/10_3.gif" alt="Ground Shading + Sinusoids Wave (three different kind of waves) + texture (offline)"></p><h1 id="11-SkyBox"><a href="#11-SkyBox" class="headerlink" title="11. SkyBox"></a>11. SkyBox</h1><p>Implementing a skybox, based on our system I have the following ideas. I spend 3 days on this , make me really depressed, it should not that hard, because there are lots of problem of bounding in fillscan of my code before.</p><ol><li>The skybox doesn’t need to introduce a zbuffer, he gets rendered first and all subsequent renders override the skybox just fine. </li><li>The skybox should have the same coord as same as camera, should tranlslate to the center point of camera, but should not rotate with it.</li><li>The skybox in some point is a cube polygon, I can simply use the module_cube algorithm before, but make the normal point to the center of the box.</li></ol><p>The image below is the skybox I init, and put it in the center of the camera. </p><div style="display: flex; justify-content: center; align-items: center;">  <img src="11_1.jpg" title="A regular image" width="300px" height="300px">  <img src="11_2.jpg" title="A regular image" width="500px" height="300px"></div><p>At the beginning, I didn’t want to use linear interpolation to compute the skybox because I thought this method would be very time-consuming. In my opinion, the correct approach should be to get the transformation matrix for each surface of the skybox, then apply this matrix to the transformation after reading the image, and map it to each face. This would greatly reduce the computational load since it wouldn’t require operations like fillScan. However, I eventually gave up because it was too complicated. I needed to record all boundary conditions and calculate the matrix for each surface. So, I ended up using the simplest method: directly applying the texture to each surface.</p><h1 id="12-Phong-Shading"><a href="#12-Phong-Shading" class="headerlink" title="12.  Phong Shading"></a>12.  Phong Shading</h1><p>Below is the water surface I simulated with phong shading, you can see that there are obvious highlights and diffuse area, but one thing is strange, I tried to give the ks as big as possible as the water surface should be, but the result is very strange, diffuse and specular features are very strong in my code, and I ended up generating a light ambient light &#x3D; diffuse&#x3D;specular, R &#x3D; 100 and got relatively good results.</p><p><img src="/2024/07/23/CS5310-final-project/13_2.gif" alt="Phong shading with ka = 0.6; kd = 0.2; ks = 0.8; R = 100"></p><h1 id="13-Alpha-Channel"><a href="#13-Alpha-Channel" class="headerlink" title="13. Alpha Channel"></a>13. Alpha Channel</h1><p><img src="/2024/07/23/CS5310-final-project/14_1.gif" alt="Alpha Channel; kd = 0.2; ks = 0.8; R = 100"></p><p>Then I combine all the staff I have right now together, here is the result </p><p><img src="/2024/07/23/CS5310-final-project/14_2.gif" alt="Alpha + Texture + Particle + Phong"></p><!-- ![Alpha + Texture + Particle + Phong](/2024/07/23/CS5310-final-project/14_3.gif) --><p>I wanna add rain right now !</p><!-- ![Alpha + Texture + Particle + Phong](/2024/07/23/CS5310-final-project/14_4.gif) --><p><img src="/2024/07/23/CS5310-final-project/14_6.gif" alt="Alpha + Texture + Particle + Phong"></p><h1 id="14-Particle"><a href="#14-Particle" class="headerlink" title="14. Particle"></a>14. Particle</h1><p>s</p><p>I initially wanted to create fog over the water surface, but I realized that without using volumetric rendering or having shadow volumes, the result was quite poor. I tried using Perlin noise to achieve this, but the outcome was very disappointing. So, I changed my approach and decided to generate clouds instead. The fake result I obtained is as follows.</p><p><img src="/2024/07/23/CS5310-final-project/15_3.gif" alt="Random the fog position"></p><p>The result is pretty bad,, I decide not to use it…</p><p><img src="/2024/07/23/CS5310-final-project/15_4.jpg" alt="Random the fog position"></p><p>Here is my final result</p><p><img src="/2024/07/23/CS5310-final-project/15_2.gif" alt="My final result before PBD"></p><h1 id="15-PBD"><a href="#15-PBD" class="headerlink" title="15. PBD"></a>15. PBD</h1><p>There’s a very famous paper to simulate water : <a href="https://mmacklin.com/pbf_sig_preprint.pdf">Position Based Fluids</a>. I really want to imply this paper, but after thoroughly understanding what I need to do, I think I’ll need half a month to a month, but I’ve only got several days, so I’m going to implement an basic algorithm of this paper: PBD.</p><h2 id="Force"><a href="#Force" class="headerlink" title="Force"></a>Force</h2><p>Build a Particle and give a Gravity to it, the particle only have several faces as you see, this is because I wanna to make my program as fast as possible.</p><p><img src="/2024/07/23/CS5310-final-project/12_1.gif" alt="Partticle + Gravity = -9.8 "></p><p>One of the most basic things about PBD is that it <code>relies on position</code> to calculate acceleration and velocity, rather than the traditional reliance on acceleration and velocity to find position. So here is the structure of my particle.</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-comment">// Particle structure for water simulation</span><br><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">Particle</span>&#123;</span><br>    Point position;  <span class="hljs-comment">// Position of the particle</span><br>    Point pred_position; <span class="hljs-comment">// Next dt position</span><br>    Vector v; <span class="hljs-comment">// Velocity of the particle</span><br>    Vector acceleration; <span class="hljs-comment">// Acceleration of the particle</span><br>    Vector vorticity;<br>    Vector externalForce;<br>    Vector oneTimeForce; <span class="hljs-comment">// only use one time and dead</span><br>    <span class="hljs-type">int</span> oneTimeForceAlive;<br>    <span class="hljs-type">float</span> mass;     <span class="hljs-comment">// Mass of the particle</span><br>    Bin neighbours;<br>    <span class="hljs-type">float</span> lambda ;<br>    <span class="hljs-type">int</span> id ;<br>    <span class="hljs-type">const</span> <span class="hljs-type">int</span> size ;<br>&#125;;<br></code></pre></td></tr></table></figure><p>I add a new function <code>Apply One Time Force</code> and <code>A Bounding box System</code> to achieve the image below, here is the thing, I can not simply add a init velocity to the system, because it is <code>position based system</code>, I can only add one time force in the system.</p><p><img src="/2024/07/23/CS5310-final-project/12_2.gif" alt="Extra Force.x = -2 ; Gravity.y = -9.8 ; damping = 0.6 "></p><p><img src="/2024/07/23/CS5310-final-project/12_3.gif" alt="Extra Force.x = -2 ; Gravity.y = -9.8 ; damping = 0.8 "></p><p><img src="/2024/07/23/CS5310-final-project/12_5.gif" alt="1000 particles"></p><p>After adding 1000 the particles to the system, we found that they can not detect each other, which menas there is no collison in the sytstem. But here is the point, how to detected the particles around each particles ? We need a new structure : Grid[][][], we put all the particles in the gird, if we wanna to find the neighbour particles around the target particles, just get all the particles from grids which around the target particles. After that, we need a new method <code>distance constraint</code> to find how to deal with the collsion by a eaiser way.</p><h2 id="Distance-Constraint"><a href="#Distance-Constraint" class="headerlink" title="Distance Constraint"></a>Distance Constraint</h2><p>The most simple constraint which is <code>distance constraint</code>, my understanding is that we need to make sure that each point is as far as possible to where we expect it to be, and if that doesn’t work then fine-tune until the whole system is close to stable.</p><p>$$\nabla C_{ij} &#x3D; \frac{p_i - p_j}{| p_i - p_j |}t$$<br>$$\lambda_i &#x3D; \frac{-C_{ij}}{\sum_k (\nabla C_{ik})^2}$$<br>$$\Delta p_i &#x3D; \lambda_i \nabla C_{ij}$$<br>$$p_i’ &#x3D; p_i + \Delta p_i$$<br>$$p_j’ &#x3D; p_j - \Delta p_i$$</p><p><img src="/2024/07/23/CS5310-final-project/12_4.gif" alt="1000 particles"></p><p>The result is as expected, but for the bottom example there is a problem, the two points merge together when compressed to the extreme, the reason for this problem is because the bounding box detection I did not set as a constraint, because the constraint is to fine-tune the points, but in any case it should not go beyond the bouding box, here you can conditionally check the constraints, but it is too complex I’ll leave it here for now.</p><p><img src="/2024/07/23/CS5310-final-project/12_7.gif" alt="10000 particles my first result"></p><p>However, the results were unsatisfactory. After investigating, I identified three key issues:</p><ol><li><p><strong>Precision Issues</strong>: The precision of my calculations was insufficient. With a particle radius of 0.03, using floats resulted in significant errors when particles experienced even slight offsets. To address this, I switched to using double precision.</p></li><li><p><strong>Constraint Accumulation Method</strong>: My initial approach to constraint distance accumulation was flawed. According to [Müller et al. 2006], the system should be solved using an iterative method similar to Gauss-Seidel for linear equations. In this method, once a constraint is calculated, the particle positions are immediately corrected, and these updated positions are then used in subsequent constraint mappings. While this approach led to faster convergence, the results were still unsatisfactory due to insufficient accuracy. My initial crude method exacerbated these issues, so I introduced a new variable, <code>buffer_position</code>, to store the corrected positions before applying them.</p></li><li><p><strong>Time Step (dt) Problems</strong>: The choice of time step (<code>dt</code>) was problematic. Since the system runs on a single thread, I had increased <code>dt</code> for convenience, which led to an excessively large search range. This caused too many particles to be affected simultaneously, increasing the likelihood of overlapping positions and, consequently, inaccurate results.</p></li></ol><p>I addressed the issues mentioned above by removing all forces and increasing the distance between points, effectively simulating a situation similar to water droplets in space. Now, the results align with expectations: the distance between each point remains constant, and the overall system maintains precision, meeting our intended outcomes.</p><p><img src="/2024/07/23/CS5310-final-project/15_12.gif" alt="Delete all force, only keep the distance constriant"></p><p>And it’s really cool! When we reverse the constraint force—meaning that when points detect an incorrect distance, they move closer together—we observe the formation of distinct small clusters, as shown in the image below. Upon closer inspection, you’ll notice that each search area forms its own cluster. Each grid in the 3D space seems to gather into a center of mass, almost like gravitational attraction.And it’s really cool! When we reverse the constraint force—meaning that when points detect an incorrect distance, they move closer together—we observe the formation of distinct small clusters, as shown in the image below. Upon closer inspection, you’ll notice that each search area forms its own cluster. Each grid in the 3D space seems to gather into a center of mass, almost like gravitational attraction.</p><p><img src="/2024/07/23/CS5310-final-project/15_5.gif" alt="Random the fog position"></p><p>I generated a series of images, with the one I’m most satisfied with at the end. There’s still room for optimization, but the main reason the results aren’t perfect is due to the limitations of single-threading. I couldn’t significantly reduce the time step <code>dt</code> and <code>constraint strength</code> to achieve a flawless outcome. However, the image below represents the best result I could achieve with my current single-threading setup.</p><div style="display: flex; justify-content: center; align-items: center;">  <img src="15_6.gif" title="A regular image" width="400px" height="200px">  <img src="15_7.gif" title="A regular image" width="400px" height="200px">  <img src="15_8.gif" title="A regular image" width="400px" height="200px"></div><div style="display: flex; justify-content: center; align-items: center;">  <img src="15_9.gif" title="A regular image" width="400px" height="200px">  <img src="15_10.gif" title="A regular image" width="400px" height="200px">  <img src="15_11.gif" title="A regular image" width="400px" height="200px"></div><p>The result above is still bad , but which is the best result I got. </p><p><img src="/2024/07/23/CS5310-final-project/15_9.gif" alt="The Best result I use Gravity + Distance Constrant"></p><h1 id="PBF"><a href="#PBF" class="headerlink" title="PBF"></a>PBF</h1><h2 id="Incompressibility"><a href="#Incompressibility" class="headerlink" title="Incompressibility"></a>Incompressibility</h2><p>The $\textbf{Poly6 kernel}$ is defined as:</p><p>$$W_{\text{poly6}}(r, h) &#x3D; \frac{315}{64\pi h^9} \cdot (h^2 - r^2)^3$$</p><p>where:</p><ul><li>( r ) is the distance between two particles.</li><li>( h ) is the smoothing length or influence radius.</li></ul><p>For $( 0 \leq r \leq h ):<br>W_{\text{poly6}}(r, h) &#x3D; \frac{315}{64\pi h^9} \cdot (h^2 - r^2)^3$</p><p>For $( r &gt; h ):W_{\text{poly6}}(r, h) &#x3D; 0$</p><p>The $\textbf{Spiky kernel}$ is defined as:  </p><p>$$W_{\text{spiky}}(r, h) &#x3D; \frac{15}{\pi h^6} \cdot (h - r)^3$$</p><p>where:</p><ul><li>( r ) is the distance between two particles.</li><li>( h ) is the searching range in our system which is the neighbour range.</li></ul><p>For $ ( 0 \leq r \leq h ):<br>W_{\text{spiky}}(r, h) &#x3D; \frac{15}{\pi h^6} \cdot (h - r)^3<br>$</p><p>For $( r &gt; h): W_{\text{spiky}}(r, h) &#x3D; 0$</p><p>Using the two kernels to calculate the expected density and gravidence of density. Here is the lamada of each particles. Then another for loop to calculate the buffer distances.</p><p>$$\lambda_i &#x3D; -\frac{C_i(p_1, \dots, p_n)}{\sum_k |\nabla_{p_k} C_i|^2 + \epsilon}$$</p><p>$$\Delta p_{i} &#x3D; \frac{1}{\text{restDistance}} \sum_j (\lambda_i + \lambda_j) \nabla W(p_i - p_j, h)$$</p><p>Where $\nabla W$ is the $\textbf{Spiky Kernel}$. </p><p>Better results were obtained based on density rather than distance. Even if our particles were denser they wouldn’t overlap each other.</p><p><img src="/2024/07/23/CS5310-final-project/15_14.gif" alt="Incompressibility"></p><h2 id="Tensile-Instability"><a href="#Tensile-Instability" class="headerlink" title="Tensile Instability"></a>Tensile Instability</h2><p>When a particle has too few neighbors, it may result in negative pressure and cause particles to clump together. One solution, which adds the effect of surface tension, is to introduce an artificial pressure to the smoothing kernel in order to repulse particles. This corrective term, described by Monaghan:</p><p>$$<br>\text{corr} &#x3D; -k \left(\frac{W(p_i - p_j, h)}{W(\Delta q, h)}\right)^n<br>$$</p><p>The final position update for particle $i$ is then:</p><p>$$<br>\Delta p_i &#x3D; \frac{1}{\rho_0} \sum_j \left(\lambda_i + \lambda_j + \text{corr}\right) \nabla W(p_i - p_j, h)<br>$$</p><p>$\Delta q &#x3D; 0.0</p><p><img src="/2024/07/23/CS5310-final-project/15_13.gif" alt="1000 particles with PBF"></p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p>[1] <a href="https://github.com/QianMo/Game-Programmer-Study-Notes/blob/master/Content/%E7%9C%9F%E5%AE%9E%E6%84%9F%E6%B0%B4%E4%BD%93%E6%B8%B2%E6%9F%93%E6%8A%80%E6%9C%AF%E6%80%BB%E7%BB%93/README.md">https://github.com/QianMo/Game-Programmer-Study-Notes/blob/master/Content/%E7%9C%9F%E5%AE%9E%E6%84%9F%E6%B0%B4%E4%BD%93%E6%B8%B2%E6%9F%93%E6%8A%80%E6%9C%AF%E6%80%BB%E7%BB%93/README.md</a><br>[2] <a href="https://northeastern.instructure.com/courses/180758">https://northeastern.instructure.com/courses/180758</a><br>[3] <a href="https://wikischool.org/divided_light">https://wikischool.org/divided_light</a><br>[4] <a href="https://blog.csdn.net/knight_lyh/article/details/56282584">https://blog.csdn.net/knight_lyh/article/details/56282584</a><br>[5] <a href="https://mmacklin.com/pbf_sig_preprint.pdf">https://mmacklin.com/pbf_sig_preprint.pdf</a><br>[6] <a href="https://blog.csdn.net/qq_36383623/article/details/104872438">https://blog.csdn.net/qq_36383623/article/details/104872438</a><br>[7] <a href="https://www.cs.cmu.edu/~scoros/cs15467-s16/lectures/11-fluids2.pdf">https://www.cs.cmu.edu/~scoros/cs15467-s16/lectures/11-fluids2.pdf</a><br>[8] <a href="http://jamesjia.com/cs184-fluidsim#spiky">http://jamesjia.com/cs184-fluidsim#spiky</a>  </p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>D3D12_learning_notes</title>
    <link href="/2023/10/18/D3D12-learning-notes/"/>
    <url>/2023/10/18/D3D12-learning-notes/</url>
    
    <content type="html"><![CDATA[<h1 id="steps"><a href="#steps" class="headerlink" title="steps"></a>steps</h1><ol><li>fully understand the meaning of each compoents</li><li>fully write the code of Hello World</li><li>build a ray casting</li><li>build a defered rendering</li></ol><h1 id="graphics-pipeline-in-DirectX-12"><a href="#graphics-pipeline-in-DirectX-12" class="headerlink" title="graphics pipeline in DirectX 12."></a>graphics pipeline in DirectX 12.</h1><p><img src="/2023/10/18/D3D12-learning-notes/3.png"></p><ol><li>Fixed-function stages (blue): cannot change how they process data, but can configure them using the DirectX 12 API. Such as imachines in a factory.</li><li>Programmable stages(green): can write a shadow program like HLSL to define exactly how data is processed. Such as a program a robot in a factory.</li></ol><ul><li><p>Input-Assembler(IA) stage: read primitive data from user-defined vertex and index buffers and assemble that data into geometric primitives.</p></li><li><p>Vertex Shader(VS) Stage<br>transform the vertex data from object-space into clip-space.</p></li><li><p>Hull Shader(HS) Stage<br>It is responsible for determining how much an input control patch should be tessellated by the tesslation.</p></li></ul><h1 id="basics-of-D3D12"><a href="#basics-of-D3D12" class="headerlink" title="basics of D3D12"></a>basics of D3D12</h1><p>Globaly learning DirectX. </p><h2 id="useful-functions"><a href="#useful-functions" class="headerlink" title="useful functions"></a>useful functions</h2><ol><li>IDXGI Factory (DirectX Graphic Infrastructure)<br>Enum Adapters and Creating Swap Chain<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-built_in">GRS_THROW_IF_FAILED</span>(<span class="hljs-built_in">CreateDXGIFactory2</span>(nDXGIFactoryFlags, <span class="hljs-built_in">IID_PPV_ARGS</span>(&amp;pIDXGIFactory5)));<br></code></pre></td></tr></table></figure></li></ol><h2 id="creating-resources"><a href="#creating-resources" class="headerlink" title="creating resources"></a>creating resources</h2><h3 id="CreateCommittedResouce"><a href="#CreateCommittedResouce" class="headerlink" title="CreateCommittedResouce"></a>CreateCommittedResouce</h3><p>implicit heap: the heap object can’t be obtained by the application. Just call the heap and use it directly, do not need to build the heap manually. But hard to control the detail of the heap.</p><h3 id="CreatePlacedResource"><a href="#CreatePlacedResource" class="headerlink" title="CreatePlacedResource"></a>CreatePlacedResource</h3><h3 id="CreatReservedResource"><a href="#CreatReservedResource" class="headerlink" title="CreatReservedResource"></a>CreatReservedResource</h3><h2 id="Heap"><a href="#Heap" class="headerlink" title="Heap"></a>Heap</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-keyword">typedef</span> <br><span class="hljs-keyword">enum</span> <span class="hljs-title class_">D3D12_HEAP_TYPE</span><br>&#123;<br>    D3D12_HEAP_TYPE_DEFAULT            = <span class="hljs-number">1</span>, <br>    D3D12_HEAP_TYPE_UPLOAD             = <span class="hljs-number">2</span>,<br>    D3D12_HEAP_TYPE_READBACK           = <span class="hljs-number">3</span>,<br>    D3D12_HEAP_TYPE_CUSTOM              = <span class="hljs-number">4</span><br>&#125; D3D12_HEAP_TYPE;<br></code></pre></td></tr></table></figure><ul><li>DEFAULT: creating buffet when D3Dxx_USAGE &#x3D; Default, only GPU  could access the data, CPU can not directly access the data. Which means it usually in $\textbf{video memory}$. Always insert some data hard to change in it, such as texture. </li><li>UPLOAD: GPU can not load the data, so upload heap is using to load the data in DEFAULT heap. For GPU “read only”, For CPU “write only”. For do not change.</li><li>READBACK: the oppsite of UPLOAD</li></ul><h2 id="Resource-Barrier"><a href="#Resource-Barrier" class="headerlink" title="Resource Barrier"></a>Resource Barrier</h2><p>Handle the parallelism problem between copy engine and graphic command engine. Ep. The texture is large enough and $\textbf{memcopy}$ need some time to copy. But the graphic command engine do not know that and already start $\textbf{Draw Call}$ the texture, which lead the unfinished texture to be rendered.</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-comment">//send the command to the command heap of copy something from UPLOAD heap to DEFAULT heap</span><br><span class="hljs-function">CD3DX12_TEXTURE_COPY_LOCATION <span class="hljs-title">Dst</span><span class="hljs-params">(pITexcute.Get(), <span class="hljs-number">0</span>)</span></span>;<br><span class="hljs-function">CD3DX12_TEXTURE_COPY_LOCATION <span class="hljs-title">Src</span><span class="hljs-params">(pITextureUpload.Get(), stTxtLayouts)</span></span>;<br><br><span class="hljs-comment">// directly command a list&#x27;s object.</span><br>pICommandList-&gt;<span class="hljs-built_in">CopyTextureRegion</span>(&amp;Dst, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, &amp;Src, <span class="hljs-literal">nullptr</span>);<br> <br><span class="hljs-comment">// Resource Barrier</span><br>D3D12_RESOURCE_BARRIER stResBar = &#123;&#125;;<br>stResBar.Type= D3D12_RESOURCE_BARRIER_TYPE_TRANSITION;<br>stResBar.Flags= D3D12_RESOURCE_BARRIER_FLAG_NONE;<br>stResBar.Transition.pResource= pITexcute.<span class="hljs-built_in">Get</span>();<br>stResBar.Transition.StateBefore = D3D12_RESOURCE_STATE_COPY_DEST;<br>stResBar.Transition.StateAfter= D3D12_RESOURCE_STATE_PIXEL_SHADER_RESOURCE;<br>stResBar.Transition.Subresource = D3D12_RESOURCE_BARRIER_ALL_SUBRESOURCES;<br> <br>pICommandList-&gt;<span class="hljs-built_in">ResourceBarrier</span>(<span class="hljs-number">1</span>, &amp;stResBar);<br></code></pre></td></tr></table></figure><p>In my understanding, because command heap’s excution on GPU is in serial order, which means rescource barrier is just like crossbars at supermarket checkout counters.</p><h2 id="Adapter"><a href="#Adapter" class="headerlink" title="Adapter"></a>Adapter</h2><p>used to looking for a adapter(graphic card)</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-function">ComPtr&lt;IDXGIAdapter4&gt; <span class="hljs-title">GetAdapter</span><span class="hljs-params">(<span class="hljs-type">bool</span> useWarp)</span></span><br><span class="hljs-function"></span>&#123;<br>    ComPtr&lt;IDXGIFactory4&gt; dxgiFactory;<br>    UINT createFactoryFlags = <span class="hljs-number">0</span>;<br><span class="hljs-meta">#<span class="hljs-keyword">if</span> defined(_DEBUG)</span><br>    createFactoryFlags = DXGI_CREATE_FACTORY_DEBUG;<br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br> <br>    <span class="hljs-built_in">ThrowIfFailed</span>(<span class="hljs-built_in">CreateDXGIFactory2</span>(createFactoryFlags, <span class="hljs-built_in">IID_PPV_ARGS</span>(&amp;dxgiFactory)));<br>   ComPtr&lt;IDXGIAdapter1&gt; dxgiAdapter1;<br>    ComPtr&lt;IDXGIAdapter4&gt; dxgiAdapter4;<br><br>    <span class="hljs-keyword">if</span> (useWarp)<br>    &#123;<br>        <span class="hljs-built_in">ThrowIfFailed</span>(dxgiFactory-&gt;<span class="hljs-built_in">EnumWarpAdapter</span>(<span class="hljs-built_in">IID_PPV_ARGS</span>(&amp;dxgiAdapter1)));<br>        <span class="hljs-built_in">ThrowIfFailed</span>(dxgiAdapter1.<span class="hljs-built_in">As</span>(&amp;dxgiAdapter4));<br>    &#125;<br>    <span class="hljs-keyword">else</span><br>    &#123;<br>        SIZE_T maxDedicatedVideoMemory = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span> (UINT i = <span class="hljs-number">0</span>; dxgiFactory-&gt;<span class="hljs-built_in">EnumAdapters1</span>(i, &amp;dxgiAdapter1) != DXGI_ERROR_NOT_FOUND; ++i)<br>        &#123;<br>            DXGI_ADAPTER_DESC1 dxgiAdapterDesc1;<br>            dxgiAdapter1-&gt;<span class="hljs-built_in">GetDesc1</span>(&amp;dxgiAdapterDesc1);<br> <br>            <span class="hljs-comment">// Check to see if the adapter can create a D3D12 device without actually </span><br>            <span class="hljs-comment">// creating it. The adapter with the largest dedicated video memory</span><br>            <span class="hljs-comment">// is favored.</span><br>            <span class="hljs-keyword">if</span> ((dxgiAdapterDesc1.Flags &amp; DXGI_ADAPTER_FLAG_SOFTWARE) == <span class="hljs-number">0</span> &amp;&amp;<br>                <span class="hljs-built_in">SUCCEEDED</span>(<span class="hljs-built_in">D3D12CreateDevice</span>(dxgiAdapter1.<span class="hljs-built_in">Get</span>(), <br>                    D3D_FEATURE_LEVEL_11_0, __uuidof(ID3D12Device), <span class="hljs-literal">nullptr</span>)) &amp;&amp; <br>                dxgiAdapterDesc1.DedicatedVideoMemory &gt; maxDedicatedVideoMemory )<br>            &#123;<br>                maxDedicatedVideoMemory = dxgiAdapterDesc1.DedicatedVideoMemory;<br>                <span class="hljs-built_in">ThrowIfFailed</span>(dxgiAdapter1.<span class="hljs-built_in">As</span>(&amp;dxgiAdapter4));<br>            &#125;<br>        &#125;<br>    &#125;<br> <br>    <span class="hljs-keyword">return</span> dxgiAdapter4;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="Command-List-Command-Allocator-Command-Queue"><a href="#Command-List-Command-Allocator-Command-Queue" class="headerlink" title="Command List, Command Allocator, Command Queue"></a>Command List, Command Allocator, Command Queue</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-comment">// DirectX 12 Objects</span><br>ComPtr&lt;ID3D12Device2&gt; g_Device;<br>ComPtr&lt;ID3D12CommandQueue&gt; g_CommandQueue;<br>ComPtr&lt;IDXGISwapChain4&gt; g_SwapChain;<br>ComPtr&lt;ID3D12Resource&gt; g_BackBuffers[g_NumFrames];<br>ComPtr&lt;ID3D12GraphicsCommandList&gt; g_CommandList;<br>ComPtr&lt;ID3D12CommandAllocator&gt; g_CommandAllocators[g_NumFrames];<br>ComPtr&lt;ID3D12DescriptorHeap&gt; g_RTVDescriptorHeap;<br>UINT g_RTVDescriptorSize;<br>UINT g_CurrentBackBufferIndex;<br></code></pre></td></tr></table></figure><ul><li><p>Comptr: it goes out of scope when COM object is no longer needed, helping to prevent memory leaks.</p></li><li><p>CommandAllocator: create and manage the memory that backs(supports) command list. Every command list need a command allocator, and each command allocator can be used with one command list at a time.</p></li><li><p>Command List: CPU records a list of commands to be executed by GPU. Such as state changes, resource barriers, drawing operations…</p></li><li><p>Command Queue: An interface through which CPU submits the recorded command lists to the GPU for execution. The GPU start excute the command as soon as CPU put command list in it.</p></li></ul><h2 id="Fence"><a href="#Fence" class="headerlink" title="Fence"></a>Fence</h2><p><img src="/2023/10/18/D3D12-learning-notes/6.png"><br>A marker let you know when GPU has finished doing its work and tell CPU, so they can be synchronised.</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-comment">// Synchronization objects</span><br><span class="hljs-comment">// a pointer used to ensure the synchronization primitive that the CPU can use to determine the eprogress of the GPU&#x27;s execution of command lists.</span><br>ComPtr&lt;ID3D12Fence&gt; g_Fence;<br><span class="hljs-comment">// the next fence value to signal the command queue</span><br><span class="hljs-type">uint64_t</span> g_FenceValue = <span class="hljs-number">0</span>;<br><span class="hljs-comment">// each frame could be &#x27;in-flight&#x27; on the command queue, this is used to keep tracked to guarantee that any resources that are still being referenced by the command queue are not overwritten.</span><br><span class="hljs-type">uint64_t</span> g_FrameFenceValues[g_NumFrames] = &#123;&#125;;<br><span class="hljs-comment">// used to hold on untill the fance has reached a specific value.</span><br>HANDLE g_FenceEvent;<br></code></pre></td></tr></table></figure><h2 id="Swap-Chain"><a href="#Swap-Chain" class="headerlink" title="Swap Chain"></a>Swap Chain</h2><p><img src="/2023/10/18/D3D12-learning-notes/4.png"></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-type">const</span> <span class="hljs-type">unit8_t</span> g_NumFrames = <span class="hljs-number">3</span>;<br></code></pre></td></tr></table></figure><p>must more than 2 if using flip ppresentation model.</p><h2 id="Transformation-Pipeline"><a href="#Transformation-Pipeline" class="headerlink" title="Transformation Pipeline"></a>Transformation Pipeline</h2><ol><li>World Transform: change each 3D model’s coordinates into world coordinates.</li><li>View Transform: $V &#x3D; T \cdot R_z \cdot R_y \cdot R_z$</li><li>Projection Transform:</li></ol><p><img src="/2023/10/18/D3D12-learning-notes/1.png"><br><img src="/2023/10/18/D3D12-learning-notes/2.png"></p><ol start="4"><li>Clip transform: ignore the part not in the camera.</li></ol><h2 id="Render-Target-View-RTV"><a href="#Render-Target-View-RTV" class="headerlink" title="Render Target View(RTV):"></a>Render Target View(RTV):</h2><p>The purpose of it is just tell GPU how to render at back buffer before swap. If without RTV, the GPU will not know where the rendered pixel should be sent.<br><img src="/2023/10/18/D3D12-learning-notes/5.png"></p><h1 id="glossary-of-CG"><a href="#glossary-of-CG" class="headerlink" title="glossary of CG"></a>glossary of CG</h1><ul><li><p>mipmap: a set of pictures, with different level of pixels. Becasue off-site viewing do not need that detailed.</p></li><li><p>SRV(shader resource view): wrapping textures in a format that the shadow can access them. Read Only. For example : a single texture, individual arrays, planes, or colors from a mipmapped texture, 3D texture, 1D texture color gradinets, etc.</p></li><li><p>UAV(unordered access view): same as SRV, but can read or write in any order, even could read&#x2F;written simultaneously by multipl,e threads without generate memory conflicts.</p></li><li><p>root signatures: link command to the resources the shaders require. It determines the type of data the shaders should expect, but does not define the actural memory or data. For graphics command list has both a graphics and compute root signature, for compute command list have one compute root signature. These root signatures are independent of each others.</p></li><li><p>Resource: all the resource could be excuted by GPU is resource in D3D12. Which is ‘ID3D12Resource’, such as rendering targets(include back buffers), textures, vertex buffers, index buffers… </p></li><li><p>G-SYNC: refresh screen and graph card together.</p></li><li><p>Window Advanced Rasterization Platform(WARP): If did not find a valiable GPU, the system will do the same step of D3D12 by CPU by WARP. It can instead all the rendering method such as rasterization, ray tracing…</p></li></ul>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Enhance and Expanding a Realistic Cloth Rendering Model</title>
    <link href="/2023/06/20/UE5_source_code_analysis/"/>
    <url>/2023/06/20/UE5_source_code_analysis/</url>
    
    <content type="html"><![CDATA[<h1 id="Realistic-Rendering-by-Mitsuba3"><a href="#Realistic-Rendering-by-Mitsuba3" class="headerlink" title="Realistic Rendering by Mitsuba3"></a>Realistic Rendering by Mitsuba3</h1><p>Based on mitsuba3 and Irawan’s cloth model, I add a new pattern of cloth by data drived, which used multi highlights in one yarn, here is the result.</p><p><img src="/2023/06/20/UE5_source_code_analysis/3.jpeg"><br><img src="/2023/06/20/UE5_source_code_analysis/2.jpeg"><br><img src="/2023/06/20/UE5_source_code_analysis/4.jpeg"><br><img src="/2023/06/20/UE5_source_code_analysis/5.jpeg"><br><img src="/2023/06/20/UE5_source_code_analysis/1.jpeg"></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
